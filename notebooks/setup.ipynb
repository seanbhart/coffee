{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Setup\n",
    "\n",
    "Let's walk through an option for coffee market analysis:\n",
    "\n",
    "<br>[Gather our data](#gather-data)\n",
    "<br>[Setup our database](#setup-database)\n",
    "<br>[Import ICO data](#import-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather our data <a class=\"anchor\" id=\"gather-data\"></a>\n",
    "\n",
    "There are many sites that offer coffee statistics, but if we really want to dig into the details of how coffee flows along the supply chain, we will need to get our hands on some detailed data points.\n",
    "\n",
    "The International Coffee Organization (ICO) is \"the main intergovernmental organization for coffee, bringing together exporting and importing Governments to tackle the challenges facing the world coffee sector through international cooperation. Its Member Governments represent 98% of world coffee production and 67% of world consumption.\"<sup>1</sup>  Although ICO data does not comprehensively cover all coffee movements, it is the single greatest source of data regarding yearly coffee movements around the globe.  Let's start there.\n",
    "\n",
    "---\n",
    "Let's go to the ICO site and find the \"Historical Data\" section.\n",
    "![ICO Historical Data](img/ICO_historical_data.png)\n",
    "<br>\n",
    "<br>\n",
    "At first glance, it can be hard to understand how the data is organized.\n",
    "![ICO Historical Data](img/ICO_historical_data2.png)\n",
    "<br>\n",
    "<br>\n",
    "We can easily see which data is gathered on a calendar basis vs. a seasonal basis (\"crop year\"), but it can be hard to initially understand which sub-sections refer to exporters vs. importers.  We will separate our data into \"seasonal\" and \"calendar\" data and the five types of commodity movements: Inventory + Production + Imports - Exports - Consumption.  We will also focus mostly on the \"SOURCE\" data, since this is originally reported data and any \"CALC\" data we should be able to calculate on our own.  We will include some imported consumption data (calculated) for convenience:\n",
    "\n",
    "```\n",
    "Description                                 |File| Origin |Movement| Database Name\n",
    "--------------------------------------------------------------------------------------------\n",
    "Supply Data\n",
    "- Total production - Crop Year              | 1A | SOURCE | export | seasonal_production\n",
    "- Domestic consumption - Crop Year          | 1B | SOURCE | export | seasonal_consumption\n",
    "- Exportable production - Crop Year         | 1C | CALC   | export | \n",
    "- Gross opening stocks - Crop Year          | 1D | SOURCE | export | seasonal_inventory\n",
    "- Exports - Crop Year                       | 1E | SOURCE | export | seasonal_exports\n",
    "\n",
    "Trade Statistics Data\n",
    "- Exports - Calendar Year                   | 2A | SOURCE | export | calendar_exports\n",
    "- Imports - Calendar Year                   | 2B | SOURCE | import | calendar_imports\n",
    "- Re-exports - Calendar Year                | 2C | SOURCE | import | calendar_exports\n",
    "\n",
    "Inventories/Consumption Data\n",
    "- Inventories - End of Year                 | 4A | SOURCE | import | calendar_inventory\n",
    "- Disappearance (consumption) - End of Year | 4B | CALC   | import | calendar_consumption\n",
    "\n",
    "Non-Member Data\n",
    "- Imports - Calendar Year                   | 5A | SOURCE | import | calendar_imports\n",
    "- Re-exports - Calendar Year                | 5B | SOURCE | import | calendar_exports\n",
    "```\n",
    "\n",
    "<br><sup>1</sup> http://www.ico.org/mission07_e.asp?section=About_Us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our database <a class=\"anchor\" id=\"setup-database\"></a>\n",
    "\n",
    "Before we can do any analysis we will need to set up our database.  We will use a PostgreSQL database on macOS.\n",
    "\n",
    "Please [install PostgreSQL](https://www.postgresql.org/) if needed.\n",
    "\n",
    "Start the postgresql service, create the `coffee` database, and enter the postgres environment:\n",
    "```\n",
    "brew services start postgresql\n",
    "createdb coffee\n",
    "psql coffee\n",
    "```\n",
    "Create the database admin and add privileges:\n",
    "```\n",
    "CREATE USER coffeeadmin WITH PASSWORD [password];\n",
    "GRANT ALL PRIVILEGES ON DATABASE coffee TO coffeeadmin;\n",
    "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO coffeeadmin;\n",
    "```\n",
    "We will need to convert text months and types of coffee to standardized IDs, so let's go ahead and manually create and fill these tables:\n",
    "```\n",
    "CREATE TABLE month (id int PRIMARY KEY, title text);\n",
    "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO coffeeadmin;\n",
    "INSERT INTO month (id, title) VALUES (1,'January');\n",
    "INSERT INTO month (id, title) VALUES (2,'February');\n",
    "INSERT INTO month (id, title) VALUES (3,'March');\n",
    "INSERT INTO month (id, title) VALUES (4,'April');\n",
    "INSERT INTO month (id, title) VALUES (5,'May');\n",
    "INSERT INTO month (id, title) VALUES (6,'June');\n",
    "INSERT INTO month (id, title) VALUES (7,'July');\n",
    "INSERT INTO month (id, title) VALUES (8,'August');\n",
    "INSERT INTO month (id, title) VALUES (9,'September');\n",
    "INSERT INTO month (id, title) VALUES (10,'October');\n",
    "INSERT INTO month (id, title) VALUES (11,'November');\n",
    "INSERT INTO month (id, title) VALUES (12,'December');\n",
    "```\n",
    "```\n",
    "CREATE TABLE coffee_type (id int, title text, symbol text);\n",
    "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO coffeeadmin;\n",
    "INSERT INTO coffee_type (id, title, symbol) VALUES (1,'Arabica','(A)');\n",
    "INSERT INTO coffee_type (id, title, symbol) VALUES (2,'Robusta','(R)');\n",
    "INSERT INTO coffee_type (id, title, symbol) VALUES (3,'Both','(A/R)');\n",
    "INSERT INTO coffee_type (id, title, symbol) VALUES (3,'Both','(R/A)');\n",
    "```\n",
    "The ICO location names are unique, but we probably want to create some tables that allow each location to have an ID and be compatible with a variety of text variations, due to language and other spelling differences we might encounter:\n",
    "```\n",
    "CREATE TABLE location (id int PRIMARY KEY, title text, parent_location_id int);\n",
    "CREATE TABLE location_name (location_id int, name text);\n",
    "```\n",
    "In the top directory is a `locations.xlsx` file I compiled with standardized location names, assigned location IDs, parent location IDs (allows us to nest locations for grouped analysis), and a list of possible variations on the location name which also include all name versions used by the ICO data.  This allows us to standardize all locations and even combine this data with other data sources later, if needed.  Let's write a Python script to pull the locations out of this Excel file and add them to the database.\n",
    "\n",
    "Remember to grant our admin account access to the new tables:\n",
    "```\n",
    "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO coffeeadmin;\n",
    "```\n",
    "\n",
    "The script to import the locations and location names is relatively simple. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = open_workbook('locations.xlsx')\n",
    "    for s in wb.sheets():\n",
    "        print('Sheet: %s' % (s.name))\n",
    "        if s.name == 'ALL':\n",
    "            for row in range(1, s.nrows):\n",
    "                id = int(s.cell(row, 0).value)\n",
    "                parent = int(s.cell(row, 1).value)\n",
    "                location = s.cell(row, 2).value\n",
    "                names = tuple(s.cell(row, 3).value.split('|'))\n",
    "                query = (\"INSERT INTO location\"\n",
    "                         \" (id,parent_location_id,title)\"\n",
    "                         \" VALUES (%s, %s, %s)\"\n",
    "                         \" RETURNING id\")\n",
    "                sql(query, id, parent, location)\n",
    "                for name in names:\n",
    "                    query = (\"INSERT INTO location_name\"\n",
    "                             \" (location_id,name)\"\n",
    "                             \" VALUES (%s, %s)\"\n",
    "                             \" RETURNING location_id\")\n",
    "                    sql(query, id, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    ". . .but we will need some support methods, so let's just execute it from the `utils` package:\n",
    "\n",
    "```\n",
    "MacBook-Air:src seanhart$ python3\n",
    "Python 3.7.5 (default, Nov  1 2019, 02:16:32) \n",
    "[Clang 11.0.0 (clang-1100.0.33.8)] on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> \n",
    ">>> import utils\n",
    ">>> utils.locations_to_db()\n",
    "Sheet: ALL\n",
    "Sheet: STANDARD\n",
    ">>> \n",
    ">>> exit()\n",
    "```\n",
    "\n",
    "Now let's check that all of the locations were processed.  We should have 206 locations and almost 250 variations on location names:\n",
    "\n",
    "```\n",
    "psql coffee\n",
    "coffee=# SELECT COUNT(*) FROM location;\n",
    " count \n",
    "-------\n",
    "   206\n",
    "(1 row)\n",
    "\n",
    "coffee=# \n",
    "coffee=# \n",
    "coffee=# SELECT COUNT(*) FROM location_name;\n",
    " count \n",
    "-------\n",
    "   248\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "Ok, that looks correct.  Let's move on to importing the supply chain data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ICO data <a class=\"anchor\" id=\"import-data\"></a>\n",
    "\n",
    "We need to extract the data from the ICO Excel files.\n",
    "\n",
    "We will need to create tables for each of the major movement types (inventory, production, imports, exports, consumption) for both seasonal and calendar data.  Seasonal data includes the harvest month and coffee type so let's add those columns in case we want to distinguish via those data points later:\n",
    "```\n",
    "CREATE TABLE seasonal_inventory (id text PRIMARY KEY, year int, harvest_month_id int, location_id int, coffee_type int, value float);\n",
    "CREATE TABLE seasonal_production (id text PRIMARY KEY, year int, harvest_month_id int, location_id int, coffee_type int, value float);\n",
    "CREATE TABLE seasonal_exports (id text PRIMARY KEY, year int, harvest_month_id int, location_id int, coffee_type int, value float);\n",
    "CREATE TABLE seasonal_consumption (id text PRIMARY KEY, year int, harvest_month_id int, location_id int, coffee_type int, value float);\n",
    "\n",
    "CREATE TABLE calendar_inventory (id text PRIMARY KEY, year int, location_id int, value float);\n",
    "CREATE TABLE calendar_imports (id text PRIMARY KEY, year int, location_id int, value float);\n",
    "CREATE TABLE calendar_exports (id text PRIMARY KEY, year int, location_id int, value float);\n",
    "CREATE TABLE calendar_consumption (id text PRIMARY KEY, year int, location_id int, value float);\n",
    "```\n",
    "Remember to grant our admin account access to the new tables:\n",
    "```\n",
    "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO coffeeadmin;\n",
    "```\n",
    "\n",
    "Now let's create and run the scripts to import the Excel data from ICO.  We will access the Excel files from the links directly so we can simply call the scripts in the future when we want to update the data.\n",
    "\n",
    "(Note that the scripts call a local `utils` file that contains some commonly used methods including the basic SQL query method that will access our database using the `psycopg2` library.)\n",
    "\n",
    "Here are the scripts we will use (in the `/data_parse` directory), but skip below and we will run them from the terminal for ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICO Seasonal Data Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .. import utils\n",
    "\n",
    "\n",
    "# Excel sheet links\n",
    "link_exporters_inventory = 'http://www.ico.org/historical/1990%20onwards/Excel/1d%20-%20Gross%20Opening%20stocks.xlsx'\n",
    "link_exporters_production = 'http://www.ico.org/historical/1990%20onwards/Excel/1a%20-%20Total%20production.xlsx'\n",
    "link_exporters_exports = 'http://www.ico.org/historical/1990%20onwards/Excel/1e%20-%20Exports%20-%20crop%20year.xlsx'\n",
    "link_exporters_consumption = 'http://www.ico.org/historical/1990%20onwards/Excel/1b%20-%20Domestic%20consumption.xlsx'\n",
    "\n",
    "# Get the month and coffee types conversions\n",
    "month_dict = utils.get_months()\n",
    "coffee_type_dict = utils.get_coffee_types()\n",
    "\n",
    "# The first column will be the location names\n",
    "# The second column will be coffee type (1=A,2=R,3=Both)\n",
    "# The third column will start the harvest data\n",
    "location_col = 0\n",
    "coffee_type_col = 1\n",
    "value_col = 2\n",
    "\n",
    "# Store the data in a local dict to sum any split locations\n",
    "# data is stored in id:value format\n",
    "data = {}\n",
    "\n",
    "\n",
    "def seasonal_data_update(link, sheet_name, data_header, db_name):\n",
    "    # Reset the dict\n",
    "    global data\n",
    "    data = {}\n",
    "\n",
    "    # Get the workbook from the link\n",
    "    wb = utils.get_workbook_at(link)\n",
    "\n",
    "    # Set the default harvest month\n",
    "    harvest_month_id = 1\n",
    "\n",
    "    # Find the correct sheet in the workbook\n",
    "    sheet = find_sheet(wb, sheet_name)\n",
    "\n",
    "    # Find the first row with the passed keyword in the first column\n",
    "    topRow = find_data_start_row(sheet, 0, data_header)\n",
    "\n",
    "    for col in range(value_col, sheet.ncols):\n",
    "        # First get the crop year - it will be two years,\n",
    "        # so grab the first two numbers for century\n",
    "        # and last two numbers for year\n",
    "        year = int(sheet.cell(topRow, col).value[0:2] + sheet.cell(topRow, col).value[5:7])\n",
    "        # The 1999/00 season will be translated to the year 1900\n",
    "        # correct this to the year 2000\n",
    "        if year == 1900:\n",
    "            year = 2000\n",
    "\n",
    "        # Grab the location data on each row for this crop year\n",
    "        for row in range(topRow+1, sheet.nrows):\n",
    "\n",
    "            # If the location cell is empty it is not a countable cell\n",
    "            if sheet.cell(row, location_col).value != \"\":\n",
    "\n",
    "                # If the location cell has the word 'group' in the text\n",
    "                # update the harvet_month to the latest month\n",
    "                group_text_start = sheet.cell(row, location_col).value.find('group')\n",
    "                if group_text_start != -1:\n",
    "                    harvest_month_text = sheet.cell(row, location_col).value[0:group_text_start - 1]\n",
    "                    harvest_month_id = month_dict[harvest_month_text]\n",
    "                    continue\n",
    "\n",
    "                # If you get to the 'Total' row, stop\n",
    "                if sheet.cell(row, location_col).value == 'Total':\n",
    "                    break\n",
    "\n",
    "                # If the first column might have two spaces at the beginning\n",
    "                # of the cell - be sure to clean up the text\n",
    "                location_name = sheet.cell(row, location_col).value\n",
    "                location_name = location_name.strip()\n",
    "                # print(location_name)\n",
    "\n",
    "                # Find the location id based off of the used name\n",
    "                location_result = utils.sql(\"SELECT location_id FROM location_name WHERE name=%s\", location_name)\n",
    "                # Raise error and skip if the location cannot be found\n",
    "                if len(location_result) < 1:\n",
    "                    print(\"ERROR - LOCATION '%s' NOT FOUND\" % (location_name))\n",
    "                    continue\n",
    "\n",
    "                # If the results have more than one tuple, we have duplicate location names\n",
    "                if len(location_result[0]) != 1:\n",
    "                    print(\"ERROR - LOCATION '%s' ENTRY ERROR\" % (location_name))\n",
    "                    continue\n",
    "\n",
    "                location_id = location_result[0][0]\n",
    "                # print(location_id)\n",
    "                id = '%s-%d-%d' % (location_id, year, harvest_month_id)\n",
    "\n",
    "                # Check to ensure the value is not empty, if so assign 0\n",
    "                value = float(0)\n",
    "                if sheet.cell(row, col).value != '':\n",
    "                    value = float(sheet.cell(row, col).value)\n",
    "\n",
    "                # Get the value to use after checking for split locations\n",
    "                value = calculate_location_total(id, value)\n",
    "\n",
    "                # Translate the coffee type\n",
    "                coffee_type = coffee_type_dict[sheet.cell(row, coffee_type_col).value]\n",
    "\n",
    "                # print('%s, %d, %d, %d, %d, %.4f' % (id, year, harvest_month_id, location_id, coffee_type, value))\n",
    "                insert = (\"INSERT INTO \" + db_name +\n",
    "                          \" (id,year,harvest_month_id,location_id,coffee_type,value)\"\n",
    "                          \" VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                          \" ON CONFLICT ON CONSTRAINT \" + db_name + \"_pkey\"\n",
    "                          \" DO UPDATE SET coffee_type=%s,value=%s\"\n",
    "                          \" RETURNING id\")\n",
    "                utils.sql(insert, id, year, harvest_month_id, location_id, coffee_type, value, coffee_type, value)\n",
    "\n",
    "\n",
    "# If a location has been split over several location names\n",
    "# the values will need to be summed\n",
    "def calculate_location_total(id, value):\n",
    "    # Check whether the id already exists - if it does,\n",
    "    # sum the previous value with the new value and\n",
    "    # return the new total value for overwriting the old value\n",
    "    new_value = 0\n",
    "    if id in data:\n",
    "        print('%s: %f' % (id, value))\n",
    "        new_value = data[id] + value\n",
    "    else:\n",
    "        new_value = value\n",
    "\n",
    "    # Record the entry in the data dict\n",
    "    data[id] = new_value\n",
    "    return new_value\n",
    "\n",
    "\n",
    "def find_data_start_row(sheet, column, text):\n",
    "    # Find the first row in the passed column with the passed text\n",
    "    for row in range(sheet.nrows):\n",
    "        if sheet.cell(row, column).value == text:\n",
    "            return row\n",
    "\n",
    "\n",
    "def find_sheet(workbook, sheet_name):\n",
    "    for s in workbook.sheets():\n",
    "        print('Sheet: %s' % (s.name))\n",
    "        if s.name == sheet_name:\n",
    "            return s\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ICO seasonal data update\")\n",
    "    seasonal_data_update(link_exporters_inventory, 'Print Table here', 'Crop years', 'seasonal_inventory')\n",
    "    seasonal_data_update(link_exporters_production, 'Production', 'Crop year', 'seasonal_production')\n",
    "    seasonal_data_update(link_exporters_exports, 'Exports', 'Crop year', 'seasonal_exports')\n",
    "    seasonal_data_update(link_exporters_consumption, 'Print Table here', 'Crop year', 'seasonal_consumption')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICO Calendar Year Data Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .. import utils\n",
    "\n",
    "\n",
    "# Excel sheet links\n",
    "link_importers_inventory = 'http://www.ico.org/historical/1990%20onwards/Excel/4a%20-%20Inventories.xlsx'\n",
    "link_importers_imports = 'http://www.ico.org/historical/1990%20onwards/Excel/2b%20-%20Imports.xlsx'\n",
    "link_importers_other_imports = 'http://www.ico.org/historical/1990%20onwards/Excel/5a%20-%20Non-member%20imports.xlsx'\n",
    "link_importers_exports = 'http://www.ico.org/historical/1990%20onwards/Excel/2c%20-%20Re-exports.xlsx'\n",
    "link_importers_other_exports = 'http://www.ico.org/historical/1990%20onwards/Excel/5b%20-%20Non-member%20re-exports.xlsx'\n",
    "link_importers_consumption = 'http://www.ico.org/historical/1990%20onwards/Excel/4b%20-%20Disappearance.xlsx'\n",
    "\n",
    "# The first column will be the location names\n",
    "# The second column will start the data\n",
    "location_col = 0\n",
    "value_col = 1\n",
    "\n",
    "# Store the data in a local dict to sum any split locations\n",
    "# data is stored in id:value format\n",
    "data = {}\n",
    "\n",
    "\n",
    "def calendar_data_update(link, sheet_name, db_name):\n",
    "    # Reset the dict\n",
    "    global data\n",
    "    data = {}\n",
    "\n",
    "    # Get the workbook from the link\n",
    "    wb = utils.get_workbook_at(link)\n",
    "\n",
    "    # Find the correct sheet in the workbook\n",
    "    sheet = find_sheet(wb, sheet_name)\n",
    "\n",
    "    # Find the first row that is not blank\n",
    "    topRow = find_data_start_row(sheet, 1)\n",
    "\n",
    "    for col in range(value_col, sheet.ncols):\n",
    "        # First get the calendar year - it will be two years,\n",
    "        # so grab the first two numbers for century\n",
    "        # and last two numbers for year\n",
    "        year = int(sheet.cell(topRow, col).value)\n",
    "\n",
    "        # Grab the location data on each row for this year\n",
    "        # skip the header row\n",
    "        for row in range(topRow+1, sheet.nrows):\n",
    "\n",
    "            # If the location cell contains the word 'inventories'\n",
    "            # or is empty it is not a countable cell\n",
    "            inventories_text_start = sheet.cell(row, location_col).value.find('Inventories')\n",
    "            if inventories_text_start == -1 and sheet.cell(row, location_col).value != \"\":\n",
    "\n",
    "                # If you get to the 'Total' row, stop\n",
    "                if sheet.cell(row, location_col).value == 'Total':\n",
    "                    break\n",
    "\n",
    "                # If the first column might have two spaces at the beginning\n",
    "                # of the cell - be sure to clean up the text\n",
    "                location_name = sheet.cell(row, location_col).value\n",
    "                location_name = location_name.strip()\n",
    "                # print(location_name)\n",
    "\n",
    "                # Find the location id based off of the used name\n",
    "                location_result = utils.sql(\"SELECT location_id FROM location_name WHERE name=%s\", location_name)\n",
    "                # Raise error and skip if the location cannot be found\n",
    "                if len(location_result) < 1:\n",
    "                    print(\"ERROR - LOCATION '%s' NOT FOUND\" % (location_name))\n",
    "                    continue\n",
    "\n",
    "                # If the results have more than one tuple, we have duplicate location names\n",
    "                if len(location_result[0]) != 1:\n",
    "                    print(\"ERROR - LOCATION '%s' ENTRY ERROR\" % (location_name))\n",
    "                    continue\n",
    "\n",
    "                location_id = location_result[0][0]\n",
    "                # print(location_id)\n",
    "                id = '%d-%d' % (location_id, year)\n",
    "\n",
    "                # Check to ensure the value is not empty, if so assign 0\n",
    "                value = float(0)\n",
    "                if sheet.cell(row, col).value != '':\n",
    "                    value = float(sheet.cell(row, col).value)\n",
    "\n",
    "                # Get the value to use after checking for split locations\n",
    "                value = calculate_location_total(id, value)\n",
    "\n",
    "                # print(\"%s, %d, %d, %d\" % (id, year, location_id, value))\n",
    "                insert = (\"INSERT INTO \" + db_name +\n",
    "                          \" (id,year,location_id,value)\"\n",
    "                          \" VALUES (%s, %s, %s, %s)\"\n",
    "                          \" ON CONFLICT ON CONSTRAINT \" + db_name + \"_pkey\"\n",
    "                          \" DO UPDATE SET value=%s\"\n",
    "                          \" RETURNING id\")\n",
    "                utils.sql(insert, id, year, location_id, value, value)\n",
    "\n",
    "\n",
    "# If a location has been split over several location names\n",
    "# the values will need to be summed\n",
    "def calculate_location_total(id, value):\n",
    "    # Check whether the id already exists - if it does,\n",
    "    # sum the previous value with the new value and\n",
    "    # return the new total value for overwriting the old value\n",
    "    new_value = 0\n",
    "    if id in data:\n",
    "        print('%s: %f' % (id, value))\n",
    "        new_value = data[id] + value\n",
    "    else:\n",
    "        new_value = value\n",
    "\n",
    "    # Record the entry in the data dict\n",
    "    data[id] = new_value\n",
    "    return new_value\n",
    "\n",
    "\n",
    "def find_data_start_row(sheet, column):\n",
    "    # Find the first row in the passed column with the passed text\n",
    "    for row in range(sheet.nrows):\n",
    "        if sheet.cell(row, column).value != '':\n",
    "            return row\n",
    "\n",
    "\n",
    "def find_sheet(workbook, sheet_name):\n",
    "    for s in workbook.sheets():\n",
    "        print('Sheet: %s' % (s.name))\n",
    "        if s.name == sheet_name:\n",
    "            return s\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ICO calendar year data update\")\n",
    "    calendar_data_update(link_importers_inventory, 'Inventories', 'calendar_inventory')\n",
    "    calendar_data_update(link_importers_imports, 'Imports', 'calendar_imports')\n",
    "    calendar_data_update(link_importers_other_imports, 'Imports', 'calendar_imports')\n",
    "    calendar_data_update(link_importers_exports, 'Re-exports', 'calendar_exports')\n",
    "    calendar_data_update(link_importers_other_exports, 'Re-exports', 'calendar_exports')\n",
    "    calendar_data_update(link_importers_consumption, 'Disappearance', 'calendar_consumption')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the calendar data import script (using the `-m` flag to use the Python module namespace) from the package root directory:\n",
    "```\n",
    "MacBook-Air:coffee seanhart$ python3 -m src.data_parse.calendar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check our database and see if the data was imported correctly:\n",
    "```\n",
    "MacBook-Air:coffee seanhart$ psql coffee\n",
    "psql (12.1)\n",
    "Type \"help\" for help.\n",
    "\n",
    "coffee=# \\d\n",
    "                List of relations\n",
    " Schema |         Name         | Type  |  Owner   \n",
    "--------+----------------------+-------+----------\n",
    " public | calendar_consumption | table | seanhart\n",
    " public | calendar_exports     | table | seanhart\n",
    " public | calendar_imports     | table | seanhart\n",
    " public | calendar_inventory   | table | seanhart\n",
    " public | coffee_type          | table | seanhart\n",
    " public | location             | table | seanhart\n",
    " public | location_name        | table | seanhart\n",
    " public | month                | table | seanhart\n",
    " public | seasonal_consumption | table | seanhart\n",
    " public | seasonal_exports     | table | seanhart\n",
    " public | seasonal_inventory   | table | seanhart\n",
    " public | seasonal_production  | table | seanhart\n",
    "(12 rows)\n",
    "\n",
    "coffee=# SELECT * FROM calendar_consumption WHERE year=2018 ORDER BY location_id DESC LIMIT 5;\n",
    "    id    | year | location_id | value \n",
    "----------+------+-------------+-------\n",
    " 100-2018 | 2018 |         100 |    29\n",
    " 99-2018  | 2018 |          99 |    87\n",
    " 98-2018  | 2018 |          98 |   715\n",
    " 97-2018  | 2018 |          97 |     0\n",
    " 96-2018  | 2018 |          96 |     0\n",
    "(5 rows)\n",
    "```\n",
    "\n",
    "We can run the same test but join with the location table to show the location titles:\n",
    "```\n",
    "coffee=# SELECT lid.title AS location,pid.title AS parent,cons.year,cons.value AS consumption\n",
    "coffee-# FROM calendar_consumption cons\n",
    "coffee-# INNER JOIN location lid ON cons.location_id=lid.id\n",
    "coffee-# INNER JOIN location pid ON lid.parent_location_id=pid.id\n",
    "coffee-# WHERE year=2018 ORDER BY location_id ASC LIMIT 5;\n",
    "  location   |   parent   | year |    consumption     \n",
    "-------------+------------+------+--------------------\n",
    " EU          | Europe     | 2018 |       44729.571005\n",
    " Japan       | Asia-North | 2018 |       7833.5956675\n",
    " Norway      | Europe     | 2018 |        734.1667393\n",
    " Russia      | Asia-North | 2018 |       4233.5037736\n",
    " Switzerland | Europe     | 2018 | 1170.2869719999999\n",
    "(5 rows)\n",
    "```\n",
    "\n",
    "We can run similar test queries on all the tables and see the data appears to be formatted correctly, and if we double-check some random rows with the Excel file the data appears to be accurate.  For additional checking, we can also run tests on the totals for each table (by year) and compare to the Excel file, if desired:\n",
    "\n",
    "(Please note that imports and exports include both the regular imports/exports files and the \"other\" imports/exports files, so each database table total will include the sum of both file totals.)\n",
    "```\n",
    "coffee=# SELECT year,SUM(value) FROM calendar_consumption GROUP BY year ORDER BY year;\n",
    " year |        sum         \n",
    "------+--------------------\n",
    " 1990 |  93551.86161529997\n",
    " 1991 | 101593.80189780003\n",
    " 1992 | 103121.07931870001\n",
    " 1993 | 108995.99266259998\n",
    " 1994 | 100591.84517909998\n",
    " 1995 | 104327.99943299996\n",
    " 1996 | 106821.23959110002\n",
    " 1997 | 105876.65767690002\n",
    " 1998 | 107891.48143409999\n",
    " 1999 | 107384.10738219999\n",
    " 2000 | 105611.71093510001\n",
    " 2001 |     108461.2095811\n",
    " 2002 | 109274.60534609997\n",
    " 2003 | 112721.15981410001\n",
    " 2004 |     116346.4352132\n",
    " 2005 | 113095.83543549998\n",
    " 2006 |     116182.3202563\n",
    " 2007 |     116589.1928358\n",
    " 2008 | 115930.80449770001\n",
    " 2009 |     113732.1700961\n",
    " 2010 |     117126.2707015\n",
    " 2011 | 116561.26319139998\n",
    " 2012 |      117207.713997\n",
    " 2013 |             119985\n",
    " 2014 |      80296.5465616\n",
    " 2015 |      80318.9926862\n",
    " 2016 |      84482.4657011\n",
    " 2017 |      82270.6014287\n",
    " 2018 |      85748.2519519\n",
    "(29 rows)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You made it!  Your database is ready for analysis.\n",
    "\n",
    "<br>[Home](coffee.ipynb)\n",
    "<br>[Producer Analysis](producers.ipynb)\n",
    "<br>[Consumer Analysis](consumers.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
